{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignement 3"
      ],
      "metadata": {
        "id": "_qO0JjuJT1fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the datasets with torch.utils.data.DataLoader (https://pytorch3d.org/tutorials/dataloaders_ShapeNetCore_R2N2)\n",
        "\n",
        "pytorch3d.ops.GraphConv (https://pytorch3d.readthedocs.io/en/latest/modules/ops.html#pytorch3d.ops.GraphConv)\n",
        "\n",
        "https://github.com/facebookresearch/pytorch3d/blob/main/pytorch3d/structures/meshes.py"
      ],
      "metadata": {
        "id": "NBvgllaigum8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the code environment"
      ],
      "metadata": {
        "id": "Ut8MPGYzT3NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuVv39-1S7NC",
        "outputId": "20e4fed5-2794-4ffc-8c8f-f62b7a2a5cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add pre-installed pytorch3d to sys.path\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/GoogleColab/pytorch3d_packages\")"
      ],
      "metadata": {
        "id": "BpP3jzlTT8qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classifier"
      ],
      "metadata": {
        "id": "zb29u1_aT_RO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from pytorch3d.datasets import ShapeNetCore\n",
        "from pytorch3d.structures import Meshes\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "\n",
        "# Unzipping the dataset\n",
        "# Note, problem with the code. For extract_path, it needs to run once and get an error,\n",
        "# then change the variable to extract_path = \"/content/ShapeNetCore/ShapeNetCore/ShapeNetCore\"\n",
        "\n",
        "zip_path = \"/content/drive/My Drive/GoogleColab/ShapeNetCore.zip\"\n",
        "extract_path = \"/content/ShapeNetCore/ShapeNetCore/ShapeNetCore/ShapeNetCore/ShapeNetCore\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(os.path.dirname(extract_path))\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "print(os.listdir(extract_path))\n",
        "\n",
        "\n",
        "# Variables\n",
        "categories = [\"03642806\", \"03211117\", \"03046257\", \"02992529\", \"02808440\"]\n",
        "category_names = [\"Laptop\", \"Monitor\", \"Clock\", \"Cellphone\", \"Bathtub\"]\n",
        "categories_to_idx = {s: i for i, s in enumerate(categories)}\n",
        "batch_size = 8\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "device = torch.device(\"cpu\") # GPU didnt work for this code\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# Help functions to build the edges\n",
        "def to_undirected(edges):\n",
        "    rev = edges[:, [1, 0]]\n",
        "    all_e = torch.cat([edges, rev], dim=0)\n",
        "    return all_e.unique(dim=0)\n",
        "\n",
        "def build_edges_from_faces(faces):\n",
        "    edges = torch.cat([\n",
        "        faces[:, [0, 1]],\n",
        "        faces[:, [1, 2]],\n",
        "        faces[:, [2, 0]]\n",
        "    ], dim=0)\n",
        "    return to_undirected(edges)\n",
        "\n",
        "\n",
        "# Converts batch of meshes into batched graph data\n",
        "def collate_shapenet(batch):\n",
        "    verts_list = [b[\"verts\"] for b in batch]\n",
        "    faces_list = [b[\"faces\"] for b in batch]\n",
        "    synset_ids = [b[\"synset_id\"] for b in batch]\n",
        "    labels = torch.tensor([categories_to_idx[sid] for sid in synset_ids], dtype=torch.long)\n",
        "\n",
        "    mesh_batch = Meshes(verts=verts_list, faces=faces_list)\n",
        "\n",
        "    xs, edges_list, batch_vec = [], [], []\n",
        "    offset = 0\n",
        "    for i, (v, f) in enumerate(zip(mesh_batch.verts_list(), mesh_batch.faces_list())):\n",
        "        edges = build_edges_from_faces(f)\n",
        "        edges_list.append(edges + offset)\n",
        "        xs.append(v)\n",
        "        batch_vec.append(torch.full((v.size(0),), i, dtype=torch.long))\n",
        "        offset += v.size(0)\n",
        "\n",
        "    verts = torch.cat(xs, dim=0)\n",
        "    edges = torch.cat(edges_list, dim=0)\n",
        "    batch_vec = torch.cat(batch_vec)\n",
        "\n",
        "    return verts, edges, batch_vec, labels\n",
        "\n",
        "\n",
        "# The graph convolutional network\n",
        "class GraphCNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, hidden_channels=64, num_classes=5, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(GraphConv(in_channels, hidden_channels))\n",
        "        for _ in range(max(0, num_layers - 2)):\n",
        "            self.convs.append(GraphConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(GraphConv(hidden_channels, hidden_channels))\n",
        "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, verts, edges, batch):\n",
        "        x = verts\n",
        "        for conv in self.convs:\n",
        "            x = F.relu(conv(x, edges))\n",
        "\n",
        "        # Global mean pooling\n",
        "        num_graphs = int(batch.max().item() + 1)\n",
        "        out = torch.zeros(num_graphs, x.size(1), device=x.device)\n",
        "        out.index_add_(0, batch, x)\n",
        "        counts = torch.bincount(batch)\n",
        "        out = out / counts.unsqueeze(-1)\n",
        "        return self.fc(out)\n",
        "\n",
        "# Getting the dataset\n",
        "dataset = ShapeNetCore(\n",
        "    data_dir=extract_path,\n",
        "    synsets=categories,\n",
        "    version=2,\n",
        "    load_textures=False\n",
        ")\n",
        "print(\"Total models loaded:\", len(dataset))\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
        "                          collate_fn=collate_shapenet, num_workers=0)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=collate_shapenet, num_workers=0)\n",
        "\n",
        "\n",
        "# Training the model\n",
        "model = GraphCNN(in_channels=3, hidden_channels=64, num_classes=len(categories)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for verts, edges, batch_vec, labels in train_loader:\n",
        "        verts, edges, batch_vec, labels = verts.to(device), edges.to(device), batch_vec.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(verts, edges, batch_vec)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    class_correct = [0]*len(categories)\n",
        "    class_total = [0]*len(categories)\n",
        "    with torch.no_grad():\n",
        "        for verts, edges, batch_vec, labels in val_loader:\n",
        "            verts, edges, batch_vec, labels = verts.to(device), edges.to(device), batch_vec.to(device), labels.to(device)\n",
        "            outputs = model(verts, edges, batch_vec)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            for i in range(labels.size(0)):\n",
        "                gt = labels[i].item()\n",
        "                pred = predicted[i].item()\n",
        "                class_total[gt] += 1\n",
        "                if gt == pred:\n",
        "                    class_correct[gt] += 1\n",
        "\n",
        "    val_acc = correct / total if total > 0 else 0.0\n",
        "    avg_loss = total_loss / (len(train_loader) if len(train_loader) > 0 else 1)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}  Loss: {avg_loss:.4f}  Val Acc: {val_acc:.4f}\")\n",
        "    for i, name in enumerate(category_names):\n",
        "        if class_total[i] > 0:\n",
        "            print(f\"  {name}: {class_correct[i]/class_total[i]:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a82eeP3ZJk1k",
        "outputId": "92d77e3d-831c-45a6-e725-3046e612f50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Dataset already extracted.\n",
            "['03642806', '02808440', '03046257', '02992529', '03211117']\n",
            "Total models loaded: 3891\n",
            "Epoch 1/5  Loss: 1.0506  Val Acc: 0.5353\n",
            "  Laptop: 0.0938\n",
            "  Monitor: 0.7830\n",
            "  Clock: 0.2366\n",
            "  Cellphone: 0.3023\n",
            "  Bathtub: 0.9464\n",
            "\n",
            "Epoch 2/5  Loss: 0.7776  Val Acc: 0.7381\n",
            "  Laptop: 0.8438\n",
            "  Monitor: 0.8255\n",
            "  Clock: 0.2061\n",
            "  Cellphone: 0.8488\n",
            "  Bathtub: 0.8690\n",
            "\n",
            "Epoch 3/5  Loss: 0.7066  Val Acc: 0.7664\n",
            "  Laptop: 0.8229\n",
            "  Monitor: 0.8113\n",
            "  Clock: 0.4427\n",
            "  Cellphone: 0.8198\n",
            "  Bathtub: 0.8750\n",
            "\n",
            "Epoch 4/5  Loss: 0.6752  Val Acc: 0.7599\n",
            "  Laptop: 0.8750\n",
            "  Monitor: 0.8915\n",
            "  Clock: 0.1756\n",
            "  Cellphone: 0.8895\n",
            "  Bathtub: 0.8512\n",
            "\n",
            "Epoch 5/5  Loss: 0.6288  Val Acc: 0.7766\n",
            "  Laptop: 0.8646\n",
            "  Monitor: 0.8255\n",
            "  Clock: 0.3053\n",
            "  Cellphone: 0.8953\n",
            "  Bathtub: 0.9107\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pytorch3d.datasets import ShapeNetCore\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from pytorch3d.io import load_objs_as_meshes\n",
        "from pytorch3d.ops import GraphConv\n",
        "from pytorch3d.datasets.utils import collate_batched_meshes # No longer needed\n",
        "from pytorch3d.structures import Meshes\n",
        "\n",
        "# -----------------------------\n",
        "# Step 0: Extract dataset\n",
        "# -----------------------------\n",
        "zip_path = \"/content/drive/My Drive/GoogleColab/ShapeNetCore.zip\"\n",
        "extract_path = \"/content/ShapeNetCore/ShapeNetCore\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Extracting ShapeNetCore dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"/content/ShapeNetCore\")\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "print(os.listdir(extract_path))\n",
        "\n",
        "dataset = ShapeNetCore(\n",
        "    extract_path,\n",
        "    version=2,             # use ShapeNetCore v2\n",
        "    load_textures=False    # disable textures to avoid issues\n",
        ")\n",
        "\n",
        "print(\"Number of models:\", len(dataset))\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch3d.ops import GraphConv\n",
        "\n",
        "\n",
        "class GraphCNN(nn.Module):\n",
        "    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, num_layers: int = 2):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "\n",
        "        # First layer\n",
        "        layers.append(GraphConv(in_channels, hidden_channels, aggr=\"mean\"))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        # Middle layers (if any)\n",
        "        for _ in range(num_layers - 2):\n",
        "            layers.append(GraphConv(hidden_channels, hidden_channels, aggr=\"mean\"))\n",
        "            layers.append(nn.ReLU())\n",
        "\n",
        "        # Last layer\n",
        "        if num_layers > 1:\n",
        "            layers.append(GraphConv(hidden_channels, out_channels, aggr=\"mean\"))\n",
        "        else:\n",
        "            layers.append(GraphConv(in_channels, out_channels, aggr=\"mean\"))\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, GraphConv):\n",
        "                x = layer(x, edge_index)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Training\n",
        "# -----------------------------\n",
        "categories = [\"03642806\", \"03211117\", \"03046257\", \"02992529\", \"02808440\"]\n",
        "category_names= [\"Laptop\", \"Monitor\", \"Clock\", \"Cellphone\", \"Bathtub\"]\n",
        "batch_size = 16\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "model = GraphCNN(len(categories)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for voxels, labels in train_loader:\n",
        "        voxels, labels = voxels.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(voxels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    class_correct = [0] * len(categories)\n",
        "    class_total = [0] * len(categories)\n",
        "    with torch.no_grad():\n",
        "        for voxels, labels in val_loader:\n",
        "            voxels, labels = voxels.to(device), labels.to(device)\n",
        "            outputs = model(voxels)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                pred = predicted[i].item()\n",
        "                class_total[label] += 1\n",
        "                if label == pred:\n",
        "                    class_correct[label] += 1\n",
        "\n",
        "    val_acc = correct / total\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Acc: {val_acc:.4f}\")\n",
        "    for i in range(len(categories)):\n",
        "        if class_total[i] > 0:\n",
        "            acc = class_correct[i] / class_total[i]\n",
        "            print(f\"Category {category_names[i]}: {acc:.4f}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "2MSlF3rAT9wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3euSceeFHsDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}