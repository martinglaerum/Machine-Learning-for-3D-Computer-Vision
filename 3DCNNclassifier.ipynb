{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignement 2\n"
      ],
      "metadata": {
        "id": "kpfTvzXs_zG4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the code environment"
      ],
      "metadata": {
        "id": "edUgLglp_5RF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1WzH5ZSM9Pe",
        "outputId": "bc66f53a-d7f3-4fdb-e816-cdd9f7f5c9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add pre-installed pytorch3d to sys.path\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/GoogleColab/pytorch3d_packages\")"
      ],
      "metadata": {
        "id": "lqrereThM_SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classifier"
      ],
      "metadata": {
        "id": "YMvw_gGd_7jP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7bAiTLeBNLFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile, shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Unzipping the dataset\n",
        "# Note, problem with the code. For extract_path, it needs to run once and get an error,\n",
        "# then change the variable to extract_path = \"/content/ShapeNetCore/ShapeNetCore/ShapeNetCore\"\n",
        "\n",
        "zip_path = \"/content/drive/My Drive/GoogleColab/ShapeNetCore.zip\"\n",
        "extract_path = \"/content/ShapeNetCore/ShapeNetCore\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "\n",
        "# Check to see that the ShapeNetCore models are found\n",
        "print(os.listdir(extract_path))\n",
        "\n",
        "\n",
        "# Variables\n",
        "categories = [\"03642806\", \"03211117\", \"03046257\", \"02992529\", \"02808440\"]\n",
        "category_names= [\"Laptop\", \"Monitor\", \"Clock\", \"Cellphone\", \"Bathtub\"]\n",
        "batch_size = 16\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Reading the binvox files:\n",
        "def read_binvox(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        if f.readline().decode().strip() != '#binvox 1':\n",
        "            raise IOError('Not a binvox file')\n",
        "\n",
        "        dims = []\n",
        "        while True:\n",
        "            line = f.readline().decode().strip()\n",
        "            if line.startswith('dim'):\n",
        "                dims = list(map(int, line.split()[1:]))\n",
        "            elif line == 'data':\n",
        "                break\n",
        "\n",
        "        raw_data = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        values, counts = raw_data[::2], raw_data[1::2]\n",
        "        data = np.repeat(values, counts).astype(np.float32)\n",
        "        return data.reshape(dims)\n",
        "\n",
        "# Dataset for the voxel files\n",
        "class VoxelDataset(Dataset):\n",
        "    def __init__(self, base_path, categories, voxel_size=32, cache=True):\n",
        "        self.samples, self.labels = [], []\n",
        "        self.category2idx = {cat: i for i, cat in enumerate(categories)}\n",
        "        self.voxel_size = voxel_size\n",
        "        self.cache = cache\n",
        "        self.cache_data = {}\n",
        "\n",
        "        for cat in categories:\n",
        "            cat_path = os.path.join(base_path, cat)\n",
        "            if not os.path.exists(cat_path):\n",
        "                continue\n",
        "            for model_id in os.listdir(cat_path):\n",
        "                f = os.path.join(cat_path, model_id, \"models\", \"model_normalized.surface.binvox\")\n",
        "                if os.path.exists(f):\n",
        "                    self.samples.append(f)\n",
        "                    self.labels.append(self.category2idx[cat])\n",
        "\n",
        "        if not self.samples:\n",
        "            print(os.listdir(base_path))\n",
        "            raise RuntimeError(\"No .binvox files found!\")\n",
        "\n",
        "        print(f\"Loaded {len(self.samples)} samples from {len(categories)} categories\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        f, label = self.samples[idx], self.labels[idx]\n",
        "\n",
        "        # cache in memory (optional, speeds up training a lot)\n",
        "        if self.cache and f in self.cache_data:\n",
        "            vox = self.cache_data[f]\n",
        "        else:\n",
        "            vox = read_binvox(f)\n",
        "            # downsample for speed\n",
        "            if vox.shape[0] != self.voxel_size:\n",
        "                factor = vox.shape[0] // self.voxel_size\n",
        "                vox = vox[::factor, ::factor, ::factor]\n",
        "            vox = torch.tensor(vox, dtype=torch.float32).unsqueeze(0)  # (1, D, H, W)\n",
        "            if self.cache:\n",
        "                self.cache_data[f] = vox\n",
        "\n",
        "        return vox, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "# 3D CNN\n",
        "class VoxelCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv3d(1, 32, 3, padding=1), nn.BatchNorm3d(32), nn.ReLU(),\n",
        "            nn.MaxPool3d(2),\n",
        "            nn.Conv3d(32, 64, 3, padding=1), nn.BatchNorm3d(64), nn.ReLU(),\n",
        "            nn.MaxPool3d(2),\n",
        "            nn.Conv3d(64, 128, 3, padding=1), nn.BatchNorm3d(128), nn.ReLU(),\n",
        "            nn.MaxPool3d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d(1),  # â†’ (B,128,1,1,1)\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Getting the dataset\n",
        "dataset = VoxelDataset(extract_path, categories, voxel_size=32, cache=True)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, num_workers=2)\n",
        "\n",
        "# Training the model\n",
        "model = VoxelCNN(len(categories)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for voxels, labels in train_loader:\n",
        "        voxels, labels = voxels.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(voxels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    class_correct = [0] * len(categories)\n",
        "    class_total = [0] * len(categories)\n",
        "    with torch.no_grad():\n",
        "        for voxels, labels in val_loader:\n",
        "            voxels, labels = voxels.to(device), labels.to(device)\n",
        "            outputs = model(voxels)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i].item()\n",
        "                pred = predicted[i].item()\n",
        "                class_total[label] += 1\n",
        "                if label == pred:\n",
        "                    class_correct[label] += 1\n",
        "\n",
        "    val_acc = correct / total\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Val Acc: {val_acc:.4f}\")\n",
        "    for i in range(len(categories)):\n",
        "        if class_total[i] > 0:\n",
        "            acc = class_correct[i] / class_total[i]\n",
        "            print(f\"Category {category_names[i]}: {acc:.4f}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNqWcD3s91o_",
        "outputId": "138bb56a-c286-460f-f777-f3800bce9653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['03211117', '03046257', '02808440', '02992529', '03642806']\n",
            "Loaded 3887 samples from 5 categories\n",
            "Epoch 1/5, Loss: 0.6544, Val Acc: 0.8972\n",
            "Category Laptop: 0.9770\n",
            "Category Monitor: 0.8873\n",
            "Category Clock: 0.7769\n",
            "Category Cellphone: 0.9390\n",
            "Category Bathtub: 0.9185\n",
            "\n",
            "\n",
            "Epoch 2/5, Loss: 0.3785, Val Acc: 0.7584\n",
            "Category Laptop: 0.8736\n",
            "Category Monitor: 0.5587\n",
            "Category Clock: 0.4077\n",
            "Category Cellphone: 0.9634\n",
            "Category Bathtub: 1.0000\n",
            "\n",
            "\n",
            "Epoch 3/5, Loss: 0.3022, Val Acc: 0.9062\n",
            "Category Laptop: 0.9885\n",
            "Category Monitor: 0.9014\n",
            "Category Clock: 0.8846\n",
            "Category Cellphone: 0.9512\n",
            "Category Bathtub: 0.8478\n",
            "\n",
            "\n",
            "Epoch 4/5, Loss: 0.2671, Val Acc: 0.9267\n",
            "Category Laptop: 1.0000\n",
            "Category Monitor: 0.8826\n",
            "Category Clock: 0.8538\n",
            "Category Cellphone: 0.9451\n",
            "Category Bathtub: 0.9783\n",
            "\n",
            "\n",
            "Epoch 5/5, Loss: 0.2379, Val Acc: 0.9049\n",
            "Category Laptop: 0.9770\n",
            "Category Monitor: 0.8826\n",
            "Category Clock: 0.8692\n",
            "Category Cellphone: 0.9512\n",
            "Category Bathtub: 0.8804\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}