{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXw0XVCIiwuJ"
      },
      "source": [
        "# Point Cloud classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv4T80tTi7HT"
      },
      "source": [
        "Setting up the code environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHNPqdB0HoQ3",
        "outputId": "23646b2e-e58f-4f79-8b4b-aa7b41bafb55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PckH9-HWIDkI"
      },
      "outputs": [],
      "source": [
        "# Add pre-installed pytorch3d to sys.path\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/GoogleColab/pytorch3d_packages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMA0uIhCi8Vq"
      },
      "source": [
        "The classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv5NvDAsIGni",
        "outputId": "7501b512-afd0-4cc8-8754-f4dc6450a269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting dataset...\n",
            "Extraction complete.\n",
            "['02808440', '03642806', '02992529', '03211117', '03046257']\n",
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/GoogleColab/pytorch3d_packages/pytorch3d/datasets/shapenet/shapenet_core.py:116: UserWarning: The following categories are included in ShapeNetCore ver.2's official mapping but not found in the dataset location /content/ShapeNetCore/ShapeNetCore: 04225987, 04074963, 03593526, 03001627, 03513137, 04460130, 04330267, 02924116, 02828884, 02876657, 02773838, 03085013, 03938244, 02880940, 03624134, 03325088, 02871439, 03761084, 03790512, 03261776, 02801938, 02818832, 02946921, 03636649, 03797390, 03948459, 03207941, 03710193, 03759954, 03928116, 04554684, 03337140, 04090263, 02933112, 02843684, 02954340, 04256520, 03467517, 03691459, 02958343, 04530566, 02942699, 03991062, 02691156, 04379243, 04401088, 02747177, 04004475, 04099429, 04468005\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total models loaded: 3891\n",
            "Epoch 1/20  Loss: 0.9112  Val Acc: 0.8716\n",
            "  Laptop: 0.9072\n",
            "  Monitor: 0.9004\n",
            "  Clock: 0.5798\n",
            "  Cellphone: 0.9766\n",
            "  Bathtub: 0.9130\n",
            "\n",
            "Epoch 2/20  Loss: 0.4322  Val Acc: 0.8986\n",
            "  Laptop: 0.9794\n",
            "  Monitor: 0.8874\n",
            "  Clock: 0.6387\n",
            "  Cellphone: 0.9825\n",
            "  Bathtub: 0.9689\n",
            "\n",
            "Epoch 3/20  Loss: 0.3605  Val Acc: 0.8755\n",
            "  Laptop: 0.9175\n",
            "  Monitor: 0.8874\n",
            "  Clock: 0.7227\n",
            "  Cellphone: 0.8363\n",
            "  Bathtub: 0.9876\n",
            "\n",
            "Epoch 4/20  Loss: 0.3321  Val Acc: 0.9178\n",
            "  Laptop: 1.0000\n",
            "  Monitor: 0.9264\n",
            "  Clock: 0.7227\n",
            "  Cellphone: 0.9532\n",
            "  Bathtub: 0.9627\n",
            "\n",
            "Epoch 5/20  Loss: 0.3029  Val Acc: 0.9127\n",
            "  Laptop: 0.9794\n",
            "  Monitor: 0.9264\n",
            "  Clock: 0.6807\n",
            "  Cellphone: 0.9591\n",
            "  Bathtub: 0.9752\n",
            "\n",
            "Epoch 6/20  Loss: 0.2869  Val Acc: 0.9230\n",
            "  Laptop: 0.9485\n",
            "  Monitor: 0.9351\n",
            "  Clock: 0.7479\n",
            "  Cellphone: 0.9532\n",
            "  Bathtub: 0.9876\n",
            "\n",
            "Epoch 7/20  Loss: 0.2823  Val Acc: 0.9153\n",
            "  Laptop: 0.9485\n",
            "  Monitor: 0.9307\n",
            "  Clock: 0.7983\n",
            "  Cellphone: 0.9006\n",
            "  Bathtub: 0.9752\n",
            "\n",
            "Epoch 8/20  Loss: 0.2706  Val Acc: 0.9076\n",
            "  Laptop: 0.9691\n",
            "  Monitor: 0.9134\n",
            "  Clock: 0.8151\n",
            "  Cellphone: 0.8596\n",
            "  Bathtub: 0.9814\n",
            "\n",
            "Epoch 9/20  Loss: 0.2747  Val Acc: 0.9178\n",
            "  Laptop: 0.9485\n",
            "  Monitor: 0.9351\n",
            "  Clock: 0.6807\n",
            "  Cellphone: 0.9825\n",
            "  Bathtub: 0.9814\n",
            "\n",
            "Epoch 10/20  Loss: 0.2560  Val Acc: 0.9050\n",
            "  Laptop: 0.9175\n",
            "  Monitor: 0.9610\n",
            "  Clock: 0.7059\n",
            "  Cellphone: 0.9708\n",
            "  Bathtub: 0.8944\n",
            "\n",
            "Epoch 11/20  Loss: 0.2556  Val Acc: 0.9114\n",
            "  Laptop: 1.0000\n",
            "  Monitor: 0.8658\n",
            "  Clock: 0.8403\n",
            "  Cellphone: 0.9240\n",
            "  Bathtub: 0.9627\n",
            "\n",
            "Epoch 12/20  Loss: 0.2463  Val Acc: 0.8883\n",
            "  Laptop: 0.9485\n",
            "  Monitor: 0.7706\n",
            "  Clock: 0.8403\n",
            "  Cellphone: 0.9532\n",
            "  Bathtub: 0.9876\n",
            "\n",
            "Epoch 13/20  Loss: 0.2356  Val Acc: 0.8986\n",
            "  Laptop: 1.0000\n",
            "  Monitor: 0.8788\n",
            "  Clock: 0.8571\n",
            "  Cellphone: 0.8830\n",
            "  Bathtub: 0.9130\n",
            "\n",
            "Epoch 14/20  Loss: 0.2420  Val Acc: 0.9255\n",
            "  Laptop: 1.0000\n",
            "  Monitor: 0.9437\n",
            "  Clock: 0.7311\n",
            "  Cellphone: 0.9649\n",
            "  Bathtub: 0.9565\n",
            "\n",
            "Epoch 15/20  Loss: 0.2287  Val Acc: 0.9320\n",
            "  Laptop: 0.9794\n",
            "  Monitor: 0.9307\n",
            "  Clock: 0.7815\n",
            "  Cellphone: 0.9825\n",
            "  Bathtub: 0.9627\n",
            "\n",
            "Epoch 16/20  Loss: 0.2315  Val Acc: 0.9281\n",
            "  Laptop: 0.9691\n",
            "  Monitor: 0.9524\n",
            "  Clock: 0.6975\n",
            "  Cellphone: 0.9825\n",
            "  Bathtub: 0.9814\n",
            "\n",
            "Epoch 17/20  Loss: 0.2315  Val Acc: 0.9307\n",
            "  Laptop: 0.9897\n",
            "  Monitor: 0.9524\n",
            "  Clock: 0.7479\n",
            "  Cellphone: 0.9649\n",
            "  Bathtub: 0.9627\n",
            "\n",
            "Epoch 18/20  Loss: 0.2262  Val Acc: 0.9255\n",
            "  Laptop: 0.9588\n",
            "  Monitor: 0.9524\n",
            "  Clock: 0.6975\n",
            "  Cellphone: 0.9766\n",
            "  Bathtub: 0.9814\n",
            "\n",
            "Epoch 19/20  Loss: 0.2183  Val Acc: 0.9243\n",
            "  Laptop: 0.9691\n",
            "  Monitor: 0.9091\n",
            "  Clock: 0.8487\n",
            "  Cellphone: 0.9415\n",
            "  Bathtub: 0.9565\n",
            "\n",
            "Epoch 20/20  Loss: 0.2154  Val Acc: 0.9101\n",
            "  Laptop: 0.9175\n",
            "  Monitor: 0.8485\n",
            "  Clock: 0.8824\n",
            "  Cellphone: 0.9357\n",
            "  Bathtub: 0.9876\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from pytorch3d.datasets import ShapeNetCore\n",
        "\n",
        "\n",
        "# Unzipping the dataset\n",
        "# Note, problem with the code. For extract_path, it might need to run once and get an error,\n",
        "# then change the variable to extract_path = \"/content/ShapeNetCore/ShapeNetCore/ShapeNetCore\"\n",
        "\n",
        "zip_path = \"/content/drive/My Drive/GoogleColab/ShapeNetCore.zip\"\n",
        "extract_path = \"/content/ShapeNetCore/ShapeNetCore\"\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(os.path.dirname(extract_path))\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "# Check to see that the ShapeNetCore models are found\n",
        "print(os.listdir(extract_path))\n",
        "\n",
        "\n",
        "# Variables\n",
        "categories = [\"03642806\", \"03211117\", \"03046257\", \"02992529\", \"02808440\"]\n",
        "category_names = [\"Laptop\", \"Monitor\", \"Clock\", \"Cellphone\", \"Bathtub\"]\n",
        "categories_to_idx = {s: i for i, s in enumerate(categories)}\n",
        "batch_size = 16\n",
        "lr = 0.001\n",
        "epochs = 20\n",
        "num_points = 500   # fixed input size for point clouds\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "# Collate function that converts a batch of ShapeNet samples into fixed-size point clouds with labels\n",
        "def collate_pointcloud(batch):\n",
        "    verts_list = [b[\"verts\"] for b in batch]\n",
        "    synset_ids = [b[\"synset_id\"] for b in batch]\n",
        "    labels = torch.tensor([categories_to_idx[sid] for sid in synset_ids], dtype=torch.long)\n",
        "\n",
        "    pcs = []\n",
        "    for v in verts_list:\n",
        "        n = v.shape[0]\n",
        "        if n >= num_points: # Check if we need to add/remove points\n",
        "            idx = torch.randperm(n)[:num_points]\n",
        "            pc = v[idx]\n",
        "        else:\n",
        "            pad = torch.zeros(num_points - n, 3)\n",
        "            pc = torch.cat([v, pad], dim=0)\n",
        "        pcs.append(pc)\n",
        "\n",
        "    pcs = torch.stack(pcs, dim=0)\n",
        "    return pcs, labels\n",
        "\n",
        "\n",
        "# Point Cloud classifier\n",
        "class PointNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "        self.mlp1 = nn.Linear(3, 64)\n",
        "        self.mlp2 = nn.Linear(64, 128)\n",
        "        self.mlp3 = nn.Linear(128, 256)\n",
        "        self.fc1 = nn.Linear(256, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.mlp1(x))\n",
        "        x = F.relu(self.mlp2(x))\n",
        "        x = F.relu(self.mlp3(x))\n",
        "        x = torch.max(x, dim=1)[0]\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "# Getting the dataset\n",
        "dataset = ShapeNetCore(\n",
        "    data_dir=extract_path,\n",
        "    synsets=categories,\n",
        "    version=2,\n",
        "    load_textures=False\n",
        ")\n",
        "print(\"Total models loaded:\", len(dataset))\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n",
        "                          collate_fn=collate_pointcloud, num_workers=0)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=collate_pointcloud, num_workers=0)\n",
        "\n",
        "\n",
        "# Training the model\n",
        "model = PointNetClassifier(num_classes=len(categories)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for pcs, labels in train_loader:\n",
        "        pcs, labels = pcs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(pcs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    class_correct = [0]*len(categories)\n",
        "    class_total = [0]*len(categories)\n",
        "    with torch.no_grad():\n",
        "        for pcs, labels in val_loader:\n",
        "            pcs, labels = pcs.to(device), labels.to(device)\n",
        "            outputs = model(pcs)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            for i in range(labels.size(0)):\n",
        "                gt = labels[i].item()\n",
        "                pred = predicted[i].item()\n",
        "                class_total[gt] += 1\n",
        "                if gt == pred:\n",
        "                    class_correct[gt] += 1\n",
        "\n",
        "    val_acc = correct / total if total > 0 else 0.0\n",
        "    avg_loss = total_loss / (len(train_loader) if len(train_loader) > 0 else 1)\n",
        "    print(f\"Epoch {epoch+1}/{epochs}  Loss: {avg_loss:.4f}  Val Acc: {val_acc:.4f}\")\n",
        "    for i, name in enumerate(category_names):\n",
        "        if class_total[i] > 0:\n",
        "            print(f\"  {name}: {class_correct[i]/class_total[i]:.4f}\")\n",
        "    print()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
